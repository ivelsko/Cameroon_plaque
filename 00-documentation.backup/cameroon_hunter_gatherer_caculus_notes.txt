# to run zipit script
./005-imv-zipit.sh <filename>

# to build a malt database
#!/usr/bin/env bash
sbatch \
-c 112 \
--mem 1950000 \
--partition=supercruncher \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-user=velsko@shh.mpg.de \
-J "MALT-Build-RSC_Pasolli2019MAGs" \
--wrap="/projects1/malt/versions/malt040/malt-build \
--step 2 \
-i /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna.gz \
-s DNA \
-d /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/maltindexed \
-t 112 -a2taxonomy /projects1/microbiome_calculus/evolution/01-data/databases/malt/raw/nucl_acc2tax-May2017.abin"


# all Pasolli, et al. 2019 MAGs are here /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/
# all oral or non-western stool Pasolli, et al. 2019 MAGs are here /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest
# cat'd into one files with 
cat *.fa > Pasolli2019MAGs.fasta
# need to combine these with the RefSeq genomes James used to make the Custom RefSeq database to the folder here
/projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz

# as below:

#!/usr/bin/env bash
sbatch \
-c 2 \
--mem 4G \
--partition=medium \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-user=velsko@shh.mpg.de \
-J "catmalt" \
--wrap="cat /projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest/Pasolli2019MAGs.fasta.gz > /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20191015.fna && pigz -n2 /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20191015.fna"
#--wrap="zcat /projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz | cat - /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest/Pasolli2019MAGs.fasta > /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna && pigz -n2 /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna"

# then run the malt build script to use all for taxonomic identification
# then need to create a tree of all of the same genomes used to build this new MALT database with PhyloPhlan2 (this is not easy to install yet, the conda install isn't ready yet)
# then need to convert the tree from PhyloPhlan2 into NCBI format for MEGAN

# use this to run MALT
#!/usr/bin/env bash
sbatch \
-c 112 \
--mem 1850000 \
--partition=supercruncher \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-type=time_limit \
--mail-user=velsko@shh.mpg.de \
-J "MaltCMCnt" \
--wrap="/projects1/microbiome_calculus/evolution/02-scripts.backup/007-malt-genbank-nt_2017_2step_85pc_supp_0.01 \
/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp/*.gz \
/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/nt-correct"

# in 02-scripts.backup
# 011-imv-maltstats.sh
# To get the mapping stats from malt runs to input into R, use the log output file and run the following code:
# malt-nt CMC only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190903.log > ../00-documentation.backup/CMC_nt_numbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190903.log > ../00-documentation.backup/CMC_nt_aligned.txt
ls ../04-analysis/malt/nt/*.rma6 > ../00-documentation.backup/CMC_nt_names.txt
paste ../00-documentation.backup/CMC_nt_names.txt ../00-documentation.backup/CMC_nt_numbers.txt ../00-documentation.backup/CMC_nt_aligned.txt > ../00-documentation.backup/CMC_nt_aligned_stats.tsv

# malt-RefSeqCustom CMC only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190925.log > ../00-documentation.backup/CMCnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190925.log > ../00-documentation.backup/CMCaligned.txt
ls ../04-analysis/malt/RefSeqCustom/*.rma6 | grep -v SRR | grep -v JAE > ../00-documentation.backup/CMCnames.txt
paste ../00-documentation.backup/CMCnames.txt ../00-documentation.backup/CMCnumbers.txt ../00-documentation.backup/CMCaligned.txt > ../00-documentation.backup/CMC_RSC_aligned_stats.tsv

# malt-RefSeqCustom HMP only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190930.log > ../00-documentation.backup/HMPnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190930.log > ../00-documentation.backup/HMPaligned.txt
ls ../04-analysis/malt/RefSeqCustom/SRR*.bam.rma6 > ../00-documentation.backup/HMPnames.txt
paste ../00-documentation.backup/HMPnames.txt ../00-documentation.backup/HMPnumbers.txt ../00-documentation.backup/HMPaligned.txt > ../00-documentation.backup/HMP_RSC_aligned_stats.tsv

# malt-RefSeqCustom JAE only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20191021.log > ../00-documentation.backup/JAEnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20191021.log > ../00-documentation.backup/JAEaligned.txt
ls ../04-analysis/malt/RefSeqCustom/JAE*.rma6 > ../00-documentation.backup/JAEnames.txt
paste ../00-documentation.backup/JAEnames.txt ../00-documentation.backup/JAEnumbers.txt ../00-documentation.backup/JAEaligned.txt > ../00-documentation.backup/JAE_RSC_aligned_stats.tsv

# malt-RefSeqCustom Yanomami only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20191218.log > ../00-documentation.backup/Yanomaminumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20191218.log > ../00-documentation.backup/Yanomamialigned.txt
ls ../04-analysis/malt/RefSeqCustom/SRR*.truncated.rma6 > ../00-documentation.backup/Yanomaminames.txt
paste ../00-documentation.backup/Yanomaminames.txt ../00-documentation.backup/Yanomaminumbers.txt ../00-documentation.backup/Yanomamialigned.txt > ../00-documentation.backup/Yanomami_RSC_aligned_stats.tsv

# combine CMC, HMP, and JAE RefSeqCustom stats files
cat ../00-documentation.backup/CMC_RSC_aligned_stats.tsv ../00-documentation.backup/HMP_RSC_aligned_stats.tsv ../00-documentation.backup/JAE_RSC_aligned_stats.tsv ../00-documentation.backup/Yanomami_RSC_aligned_stats.tsv > ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv

rm ../00-documentation.backup/*numbers.txt
rm ../00-documentation.backup/*aligned.txt
rm ../00-documentation.backup/*names.txt

# now add column titles (SampleID, Queries, Aligned) with ./add_malt_stats_headers.rb

##########################################################################################
# symlink the HMP data for Eager processing (and subsampling)
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061294
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062298
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062299
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513165
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513768
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513775
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514202
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514239
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514306
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514329
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061192
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061320
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061365
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061562
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062083
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR063517
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR1804664
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR1804823
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR512767
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513828

# subsample the HMP samples to 10000000 reads each to be more similar to the read number of the CMC samples

#!/bin/bash

#SBATCH -n 8
#SBATCH --mem 24G
#SBATCH --partition=medium
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH --export=ALL
#SBATCH --array=0-19%2
#SBATCH -J "subsample"

SAMPLES=($(find /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/*/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d_ -f 1))
SAMPLENAME=${SAMPLES[$SLURM_ARRAY_TASK_ID]}

seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R1_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R2_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R2_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R2_000.10M.fastq

# symlink the JAE data for Eager processing (and subsampling)
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE006.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE007.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE008.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE009.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE010.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE012.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE013.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE014.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE015.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE016.A0101

#!/bin/bash

#SBATCH -n 8
#SBATCH --mem 24G
#SBATCH --partition=medium
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH --export=ALL
#SBATCH --array=0-19%2
#SBATCH -J "subsample"

SAMPLES=($(find /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d_ -f 1))
SAMPLENAME=${SAMPLES[$SLURM_ARRAY_TASK_ID]}

# need to run conda activate py27 before running /projects1/microbiome_calculus/Cameroon_plaque/02-scripts.backup/014-imv-humann2.sh
seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R1_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq

####
# to change the names of the HUMAnN2 folders that didn't match the basename do
rename 's/_S0_L001_R1_001.fastq.combined.fq.prefixed.extractunmapped.bam.10M.fastq.gz/.10M/' *_S0_L001_R1_001.fastq.combined.fq.prefixed.extractunmapped.bam.10M.fastq.gz
rename 's/_S0_L001_R1_000.10M.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz/.10M/' *_S0_L001_R1_000.10M.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz
rename 's/_S0_L001_R1_000.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz//' *_S0_L001_R1_000.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz
rename 's/.fastq.truncated.prefixed.gz//' *.fastq.truncated.prefixed.gz


mkdir genefamilies pathabundance pathcoverage

ls | while read line; do cp $line/*genefamilies.tsv ./genefamilies; done
ls | while read line; do cp $line/*pathabundance.tsv ./pathabundance; done
ls | while read line; do cp $line/*pathcoverage.tsv ./pathcoverage; done

# merge the output files and normalize them for direct comparison of samples within each output type
humann2_join_tables -i genefamilies -o humann2.genefamilies.all.tsv
humann2_renorm_table -i humann2.genefamilies.all.tsv -o humann2.genefamilies.all.tss.tsv -s y

humann2_join_tables -i pathabundance -o humann2.pathabundance.all.tsv
humann2_renorm_table -i humann2.pathabundance.all.tsv -o humann2.pathabundance.all.tss.tsv -s n

humann2_join_tables -i pathcoverage -o humann2.pathcoverage.all.tsv
humann2_renorm_table -i humann2.pathcoverage.all.tsv -o humann2.pathcoverage.all.tss.tsv -s n

mkdir genefamilies/renormed
for f in ./genefamilies/*.tsv; do humann2_renorm_table -i $f -o ./genefamilies/renormed/$(basename $f .tsv).tss.tsv; done

# download databases for regrouping entries
humann2_databases --download utility_mapping full /projects1/users/velsko/bin/humann2_regroup_databases

humann2_join_tables -i ./genefamilies/renormed -o ./humann2.genefamilies.all.i.tss.tsv
humann2_regroup_table --input humann2.genefamilies.all.i.tss.tsv --output ./humann2.genefamilies.all.i.tss.ko.tsv --groups uniref90_ko
humann2_renorm_table -i ./humann2.genefamilies.all.i.tss.ko.tsv -o ./humann2.genefamilies.all.i.tss.renorm.ko.tsv -s y

# To determine the # of reads that were aligned (or rather unaligned) by HUMAnN2
# working dir /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/humann2/input
ls *.gz > samples.list
touch samples.lines
for f in *.gz; do zcat $f | wc -l >> samples.lines; done
# add a header to each file (SampleID, Lines)
paste samples.list samples.lines > ../../../05-results.backup/sample_lines.tsv 
# check that these numbers, divided by 4, are the same as those in the metadata file column Individual_Seq_Depth_NonHuman
# if they are, use that metadata column for the R analyses, otherwise figure out why that column is wrong and fix it to match these. Use it with the correct numbers

cd ../logfiles/
touch files.names unaligned.pcts
for f in *.out; do grep "Creating output" $f | sed 's/Creating\ output\ directory\:\ \/projects1\/microbiome_calculus\/Cameroon_plaque\/04-analysis\/humann2\/output\///g' >> files.names; done
for f in *.out; do grep "Unaligned reads after translated alignment:" $f | sed 's/Unaligned\ reads\ after\ translated\ alignment\://g' | sed 's/\ \%//g' >> unaligned.pcts; done
# add a header to each file (SampleID, UnalignedPct)
paste files.names unaligned.pcts > ../../../05-results.backup/humann2_alignment_stats.tsv


###########################
run kraken 5X with both databases to see if there are more reads assigned when including MAGs, account for variability with the 5 runs
# get the number of classified and unclassified reads for each sample for each run with each database to compare 
# if adding the Pasolli MAGs to the database increases the number of reads classified in each sample

# **Note** there was no difference in the number of reads assigned in each sample between the 5 runs, so when running again use only 3 runs

# the MetaPhlAn2-type output may be too difficult to work with, so re-run with 3 runs each using the standard output format

# **Note** there is a problem with Kraken2, where it will call reads classified 'C' but have them at rank '0'
# in the report file then, the number of unclassified + root reads doesn't equal the total. The missing reads are those above. 
# These reads are not included in the report file, but are included in the output file. Apparently the developers are aware of the problem and working on it

# run this for both outputs (RefSeqOnly, RefSeqPasolliMAGs). Add .rso to the files that had the RefSeqOnly database
ls *.output.* > sampleorder.rso.list
ls *.output.* > sampleorder.rspm.list

touch classifiedreads.rso.counts
for f in *.output.*; do grep -c "^C" $f >> classifiedreads.rso.counts; done
touch unclassifiedreads.rso.counts
for f in *.output.*; do grep -c "^U" $f >> unclassifiedreads.rso.counts; done

# open each file (sampleorder.list, classifiedreads.counts, unclassifiedreads.counts) and give each a header
# SampleID, Classified, Unclassified, respectively

paste sampleorder.rspm.list classifiedreads.rspm.counts unclassifiedreads.rspm.counts > readclassification_stats.rspm.tsv
paste sampleorder.rso.list classifiedreads.rso.counts unclassifiedreads.rso.counts > readclassification_stats.rso.tsv
cp readclassification_stats.rspm.tsv /projects1/microbiome_calculus/Cameroon_plaque/05-results.backup/readclassification_stats.rspm.tsv
cp readclassification_stats.rso.tsv /projects1/microbiome_calculus/Cameroon_plaque/05-results.backup/readclassification_stats.rso.tsv

# Now load these files (readclassification_stats.tsv, readclassification_stats.rso.tsv) into R to compare the number of classified reads. Is it higher when using the database with the Pasolli MAGs?

# to get taxonomy for the standard report files:
# in /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqOnly/no_header
# in /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqPasolliMAGs/no_header

touch taxonomy.list
for f in *.old
do
awk -F"\t" '{print $1}' $f >> taxonomy.list
done
sort taxonomy.list | uniq > taxonomy.list.uniq


touch taxonomy.list
for f in *.old
do
awk -F"\t" '{print $1}' $f >> taxonomy.list
done
sort taxonomy.list | uniq > taxonomy.list.uniq

awk -F"\|" '{print $NF}' taxonomy.list.uniq | sed 's/d__//g' | sed 's/p__//g' | sed 's/c__//g' | sed 's/o__//g' | sed 's/f__//g' | sed 's/g__//g' | sed 's/s__//g' | paste - taxonomy.list.uniq > taxonomy.list.uniq.split
cat /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqPasolliMAGs/no_header/taxonomy.list.uniq.split /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqOnly/no_header/taxonomy.list.uniq.split | sort | uniq > /projects1/microbiome_calculus/Cameroon_plaque/00-documentation.backup/taxonomy.list.uniq.split

# open file and add column names SciName and Taxonomy

# open taxonomy_na.tsv and add in the appropriate taxonomy

###########################
To download oral bacteriophage sequences from MG-RAST

wget ftp://ftp.metagenomics.anl.gov/tools/download/mg-download.py
chmod u+x mg-download.py

source activate 2.7
mg-download.py --project mgp7236 --dir /projects1/microbiome_sciences/raw_data/public/abeles2014

# run the Abeles 2014 data through FastQC to see if there are adapters that need removing
TACGAGTATGCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG	
CGTAGACTAGCCTACGGGAGGCAGCAGTGAGGAATATTGGTCAATGGGCG
ACGACTACAGCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG
ACGAGTGCGTCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG


# try running the reads through cutadapt to match the parameters that were used by Abeles, et al. 2014
cutadapt -a GCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG -m 50 -M 300 --max-n 0.25 -j <NumberOfCores> -o <output.fastq.gz> <input.fastq.gz>
cutadapt -u 10 -o trimmed.fastq reads.fastq # to cut off 10 bases from the begining


# assemble the phage reads with SPAdes
sbatch 018-assemblephage.sh

# check assemblies with quast (or metaquast?)
019-imv-quast.sh /projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/scaffolds.list


# index the phage sequences from the assemblies in /projects1/microbiome_calculus/Cameroon_plaque/01-data/databases
bwa index -p abeles2014phage /projects1/microbiome_calculus/Cameroon_plaque/01-data/databases/abeles2014phage.fastq.gz




find /projects1/microbiome_sciences/raw_data/public/abeles2014/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d. -f 1 | awk '{print "/projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/"$1"/scaffolds.fasta"}' > contig.list


find /projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/*/ -name '*ds.fasta' -type f | rev | cut -d/ -f 2 | rev | cut -d. -f1 | grep -v K | grep -v misc

########################################################

# assemble the data

nextflow run nf-core/mag \
--reads '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/input/*.R{1,2}.fastq.gz' \
-profile shh \
--kraken2_db 'ftp://ftp.ccb.jhu.edu/pub/data/kraken2_dbs/minikraken2_v2_8GB_201904_UPDATE.tgz'  \
--outdir '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output' \
-name 'cmc_assembly' \
-w '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output/work'

# this is the database Alex made, but it doesn't work with this pipeline
# --kraken2_db '/projects1/microbiome_sciences/reference_databases/refseq20191017_Pasolli2019/kraken2_db/for_nf-core-mag/MiniKraken_RefSeq1910PlusPasolliSGBs.tar.gz'  \


# to resume a stalled run after deleting files
nextflow run nf-core/mag --reads '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/input/*.R{1,2}.fastq.gz' -profile shh --kraken2_db 'ftp://ftp.ccb.jhu.edu/pub/data/kraken2_dbs/minikraken2_v2_8GB_201904_UPDATE.tgz'  --outdir '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output' -w '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output/work' -resume cmc_assembly


########################################################

snakemake -s aadder.Snakefile --cluster-config aadder-cluster.config --cluster 'sbatch --mem {cluster.mem} -p {cluster.partition} -o {cluster.out} -e {cluster.err} -n {threads}' -j 1 # -n # for a test run

snakemake -s aadder_SEED_fada_ols.Snakefile --cluster-config fa_seed-cluster.config --cluster 'sbatch --mem {cluster.mem} -p {cluster.partition} -o {cluster.out} -e {cluster.err} -n {threads}' -j -n # for a test run

########################################################
# Taxonomy differences between Kraken assignemnts with RefSeqOnly and RefSeq+PasolliMAGs
# pre-MetacodeR file fixes
# fixing the taxonomy names in 00-documentation.backup/all_taxonomy_filtered_hand.csv
sed 's/VIruses/Viruses/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed.csv
sed 's/root\|d__Viruses/root\|_d__Viruses/g' all_taxonomy_filtered_hand-fixed.csv > all_taxonomy_filtered_hand-fixed2.csv
rm all_taxonomy_filtered_hand-fixed.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Eukaryota/root\|_d__Eukaryota/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
sed 's/Eukaryotas/Eukaryota/g' all_taxonomy_filtered_hand-fixed2.csv > all_taxonomy_filtered_hand-fixed3.csv
rm all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed3.csv all_taxonomy_filtered_hand.csv
sed 's/d__Eukaryota/d__Fungi/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Fungi/root\|_d__Fungi/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/\|k__Fungi//g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Bacteria/root\|_d__Bacteria/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Archaea/root\|_d__Archaea/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv



########################################################
# Songbird for differential abundance

# convert species and genus tables into biom format
biom convert -i malt_species_decontam.tsv -o malt_species_decontam.biom --to-hdf5 --table-type="OTU table"
biom convert -i malt_species_cmc_decontam.tsv -o malt_species_cmc_decontam.biom --to-hdf5 --table-type="OTU table"
biom convert -i malt_genus_decontam.tsv -o malt_genus_decontam.biom --to-hdf5 --table-type="OTU table"
biom convert -i malt_genus_cmc_decontam.tsv -o malt_genus_cmc_decontam.biom --to-hdf5 --table-type="OTU table"

# to check that the conversion worked try:
biom convert -i malt_genus_decontam.biom -o otu_table.txt --to-tsv

# run Tensorboard:
tensorboard --logdir .

# Tensorboard url:
http://mpi-sdag1.sdag.ppj.shh.mpg.de:6006

# For the formula pick from the parameters:
Ethnic_Group+Village+Market_economy+Market_economy_split+Age_group+Sex+Tooth_site

# to do: *malt_species_decontam.biom, malt_species_cmc_decontam.biom
# done: malt_genus_decontam.biom, malt_genus_cmc_decontam.biom

# for all samples
# for genus these all are higher than the null model, none are "good"
--form0 "1" # this is the null model
--form1 "Village+Ethnic_Group+Industry+Tooth_site"
--form2 "Village+Tooth_site"
--form3 "Village+Sex"
--form4 "Tooth_site"
-form5 "Sex"
-form6 "Village"
-form7 "Market_economy"
-form8 "Industry"


# for cmc samples only
# for genus form7 appears to perform the best, reaching the lowest plateau below 
# the null model and having the lowest cross-validation error; form 6 is a close 2nd based
# on the plateau and cv error; form4 has the lowest loss but plateaus higher than form0 

form0 "1" # this is the null model
form1 "Village+Ethnic_Group+Market_economy+Tooth_site"
form2 "Village+Tooth_site"
-form3 "Village+Sex"
-form4 "Tooth_site"
-form5 "Sex"
-form6 "Village"
-form7 "Market_economy"





# to run zipit script
./005-imv-zipit.sh <filename>

# to build a malt database
#!/usr/bin/env bash
sbatch \
-c 112 \
--mem 1950000 \
--partition=supercruncher \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-user=velsko@shh.mpg.de \
-J "MALT-Build-RSC_Pasolli2019MAGs" \
--wrap="/projects1/malt/versions/malt040/malt-build \
--step 2 \
-i /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna.gz \
-s DNA \
-d /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/maltindexed \
-t 112 -a2taxonomy /projects1/microbiome_calculus/evolution/01-data/databases/malt/raw/nucl_acc2tax-May2017.abin"


# all Pasolli, et al. 2019 MAGs are here /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/
# all oral or non-western stool Pasolli, et al. 2019 MAGs are here /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest
# cat'd into one files with 
cat *.fa > Pasolli2019MAGs.fasta
# need to combine these with the RefSeq genomes James used to make the Custom RefSeq database to the folder here
/projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz

# as below:

#!/usr/bin/env bash
sbatch \
-c 2 \
--mem 4G \
--partition=medium \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-user=velsko@shh.mpg.de \
-J "catmalt" \
--wrap="cat /projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest/Pasolli2019MAGs.fasta.gz > /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20191015.fna && pigz -n2 /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20191015.fna"
#--wrap="zcat /projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz | cat - /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest/Pasolli2019MAGs.fasta > /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna && pigz -n2 /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna"

# then run the malt build script to use all for taxonomic identification
# then need to create a tree of all of the same genomes used to build this new MALT database with PhyloPhlan2 (this is not easy to install yet, the conda install isn't ready yet)
# then need to convert the tree from PhyloPhlan2 into NCBI format for MEGAN

# use this to run MALT
#!/usr/bin/env bash
sbatch \
-c 112 \
--mem 1850000 \
--partition=supercruncher \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-type=time_limit \
--mail-user=velsko@shh.mpg.de \
-J "MaltCMCnt" \
--wrap="/projects1/microbiome_calculus/evolution/02-scripts.backup/007-malt-genbank-nt_2017_2step_85pc_supp_0.01 \
/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp/*.gz \
/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/nt-correct"

# in 02-scripts.backup
# 011-imv-maltstats.sh
# To get the mapping stats from malt runs to input into R, use the log output file and run the following code:
# malt-nt CMC only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190903.log > ../00-documentation.backup/CMC_nt_numbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190903.log > ../00-documentation.backup/CMC_nt_aligned.txt
ls ../04-analysis/malt/nt/*.rma6 > ../00-documentation.backup/CMC_nt_names.txt
paste ../00-documentation.backup/CMC_nt_names.txt ../00-documentation.backup/CMC_nt_numbers.txt ../00-documentation.backup/CMC_nt_aligned.txt > ../00-documentation.backup/CMC_nt_aligned_stats.tsv

# malt-RefSeqCustom CMC only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190925.log > ../00-documentation.backup/CMCnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190925.log > ../00-documentation.backup/CMCaligned.txt
ls ../04-analysis/malt/RefSeqCustom/*.rma6 | grep -v SRR | grep -v JAE > ../00-documentation.backup/CMCnames.txt
paste ../00-documentation.backup/CMCnames.txt ../00-documentation.backup/CMCnumbers.txt ../00-documentation.backup/CMCaligned.txt > ../00-documentation.backup/CMC_RSC_aligned_stats.tsv

# malt-RefSeqCustom HMP only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190930.log > ../00-documentation.backup/HMPnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190930.log > ../00-documentation.backup/HMPaligned.txt
ls ../04-analysis/malt/RefSeqCustom/SRR*.bam.rma6 > ../00-documentation.backup/HMPnames.txt
paste ../00-documentation.backup/HMPnames.txt ../00-documentation.backup/HMPnumbers.txt ../00-documentation.backup/HMPaligned.txt > ../00-documentation.backup/HMP_RSC_aligned_stats.tsv

# malt-RefSeqCustom JAE only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20191021.log > ../00-documentation.backup/JAEnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20191021.log > ../00-documentation.backup/JAEaligned.txt
ls ../04-analysis/malt/RefSeqCustom/JAE*.rma6 > ../00-documentation.backup/JAEnames.txt
paste ../00-documentation.backup/JAEnames.txt ../00-documentation.backup/JAEnumbers.txt ../00-documentation.backup/JAEaligned.txt > ../00-documentation.backup/JAE_RSC_aligned_stats.tsv

# malt-RefSeqCustom Yanomami only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20191218.log > ../00-documentation.backup/Yanomaminumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20191218.log > ../00-documentation.backup/Yanomamialigned.txt
ls ../04-analysis/malt/RefSeqCustom/SRR*.truncated.rma6 > ../00-documentation.backup/Yanomaminames.txt
paste ../00-documentation.backup/Yanomaminames.txt ../00-documentation.backup/Yanomaminumbers.txt ../00-documentation.backup/Yanomamialigned.txt > ../00-documentation.backup/Yanomami_RSC_aligned_stats.tsv

# combine CMC, HMP, and JAE RefSeqCustom stats files
cat ../00-documentation.backup/CMC_RSC_aligned_stats.tsv ../00-documentation.backup/HMP_RSC_aligned_stats.tsv ../00-documentation.backup/JAE_RSC_aligned_stats.tsv ../00-documentation.backup/Yanomami_RSC_aligned_stats.tsv > ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv

rm ../00-documentation.backup/*numbers.txt
rm ../00-documentation.backup/*aligned.txt
rm ../00-documentation.backup/*names.txt

# now add column titles (SampleID, Queries, Aligned) with ./add_malt_stats_headers.rb

##########################################################################################
# symlink the HMP data for Eager processing (and subsampling)
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061294
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062298
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062299
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513165
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513768
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513775
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514202
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514239
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514306
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514329
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061192
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061320
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061365
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061562
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062083
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR063517
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR1804664
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR1804823
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR512767
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513828

# subsample the HMP samples to 10000000 reads each to be more similar to the read number of the CMC samples

#!/bin/bash

#SBATCH -n 8
#SBATCH --mem 24G
#SBATCH --partition=medium
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH --export=ALL
#SBATCH --array=0-19%2
#SBATCH -J "subsample"

SAMPLES=($(find /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/*/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d_ -f 1))
SAMPLENAME=${SAMPLES[$SLURM_ARRAY_TASK_ID]}

seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R1_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R2_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R2_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R2_000.10M.fastq

# symlink the JAE data for Eager processing (and subsampling)
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE006.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE007.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE008.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE009.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE010.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE012.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE013.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE014.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE015.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE016.A0101

#!/bin/bash

#SBATCH -n 8
#SBATCH --mem 24G
#SBATCH --partition=medium
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH --export=ALL
#SBATCH --array=0-19%2
#SBATCH -J "subsample"

SAMPLES=($(find /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d_ -f 1))
SAMPLENAME=${SAMPLES[$SLURM_ARRAY_TASK_ID]}

# need to run conda activate py27 before running /projects1/microbiome_calculus/Cameroon_plaque/02-scripts.backup/014-imv-humann2.sh
seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R1_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq

####
# to change the names of the HUMAnN2 folders that didn't match the basename do
rename 's/_S0_L001_R1_001.fastq.combined.fq.prefixed.extractunmapped.bam.10M.fastq.gz/.10M/' *_S0_L001_R1_001.fastq.combined.fq.prefixed.extractunmapped.bam.10M.fastq.gz
rename 's/_S0_L001_R1_000.10M.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz/.10M/' *_S0_L001_R1_000.10M.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz
rename 's/_S0_L001_R1_000.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz//' *_S0_L001_R1_000.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz


mkdir genefamilies pathabundance pathcoverage

ls | while read line; do cp $line/*genefamilies.tsv ./genefamilies; done
ls | while read line; do cp $line/*pathabundance.tsv ./pathabundance; done
ls | while read line; do cp $line/*pathcoverage.tsv ./pathcoverage; done

# merge the output files and normalize them for direct comparison of samples within each output type
humann2_join_tables -i genefamilies -o humann2.genefamilies.all.tsv
humann2_renorm_table -i humann2.genefamilies.all.tsv -o humann2.genefamilies.all.tss.tsv -s y

humann2_join_tables -i pathabundance -o humann2.pathabundance.all.tsv
humann2_renorm_table -i pathabundance.all.tsv -o humann2.pathabundance.all.tss.tsv -s n

humann2_join_tables -i pathcoverage -o humann2.pathcoverage.all.tsv
humann2_renorm_table -i humann2.pathcoverage.all.tsv -o humann2.pathcoverage.all.tss.tsv -s n

mkdir genefamilies/renormed
for f in ./genefamilies/*.tsv; do humann2_renorm_table -i $f -o ./genefamilies/renormed/$(basename $f .tsv).tss.tsv; done

# download databases for regrouping entries
humann2_databases --download utility_mapping full ~/bin/humann2_regroup_databases

humann2_join_tables -i ./genefamilies/renormed -o ./humann2.genefamilies.all.i.tss.tsv
humann2_regroup_table --input humann2.genefamilies.all.i.tss.tsv --output ./humann2.genefamilies.all.i.tss.ko.tsv --groups uniref90_ko
humann2_renorm_table -i ./humann2.genefamilies.all.i.tss.ko.tsv -o ./humann2.genefamilies.all.i.tss.renorm.ko.tsv -s y

###########################
run kraken 10X with both databases to see if there are more reads assigned when including MAGs, account for variability with the 10 runs
# get the number of classified and unclassified reads for each sample for each run with each database to compare 
# if adding the Pasolli MAGs to the database increases the number of reads classified in each sample

# run this for both outputs (RefSeqOnly, RefSeqPasolliMAGs). Add .rso to the files that had the RefSeqOnly database
ls *.output.* > sampleorder.list

touch classifiedreads.counts
for f in *.output.*; do grep -c "^C" $f >> classifiedreads.counts; done
touch unclassifiedreads.counts
for f in *.output.*; do grep -c "^U" $f >> unclassifiedreads.counts; done

# open each file (sampleorder.list, classifiedreads.counts, unclassifiedreads.counts) and give each a header
# SampleID, Classified, Unclassified, respectively

paste sampleorder.list classifiedreads.counts unclassifiedreads.counts > readclassification_stats.tsv

# Now load these files (readclassification_stats.tsv, readclassification_stats.rso.tsv) into R to compare the number of classified reads. Is it higher when using the database with the Pasolli MAGs?


###########################
To download oral bacteriophage sequences from MG-RAST

wget ftp://ftp.metagenomics.anl.gov/tools/download/mg-download.py
chmod u+x mg-download.py

source activate 2.7
mg-download.py --project mgp7236 --dir /projects1/microbiome_sciences/raw_data/public/abeles2014

# run the Abeles 2014 data through FastQC to see if there are adapters that need removing
TACGAGTATGCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG	
CGTAGACTAGCCTACGGGAGGCAGCAGTGAGGAATATTGGTCAATGGGCG
ACGACTACAGCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG
ACGAGTGCGTCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG


# try running the reads through cutadapt to match the parameters that were used by Abeles, et al. 2014
cutadapt -a GCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG -m 50 -M 300 --max-n 0.25 -j <NumberOfCores> -o <output.fastq.gz> <input.fastq.gz>
cutadapt -u 10 -o trimmed.fastq reads.fastq # to cut off 10 bases from the begining


# assemble the phage reads with SPAdes
sbatch 018-assemblephage.sh

# check assemblies with quast (or metaquast?)
019-imv-quast.sh /projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/scaffolds.list


# index the phage sequences from the assemblies in /projects1/microbiome_calculus/Cameroon_plaque/01-data/databases
bwa index -p abeles2014phage /projects1/microbiome_calculus/Cameroon_plaque/01-data/databases/abeles2014phage.fastq.gz




find /projects1/microbiome_sciences/raw_data/public/abeles2014/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d. -f 1 | awk '{print "/projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/"$1"/scaffolds.fasta"}' > contig.list


find /projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/*/ -name '*ds.fasta' -type f | rev | cut -d/ -f 2 | rev | cut -d. -f1 | grep -v K | grep -v misc














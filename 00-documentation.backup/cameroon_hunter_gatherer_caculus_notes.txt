# to run zipit script
./005-imv-zipit.sh <filename>

# to build a malt database
#!/usr/bin/env bash
sbatch \
-c 112 \
--mem 1950000 \
--partition=supercruncher \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-user=velsko@shh.mpg.de \
-J "MALT-Build-RSC_Pasolli2019MAGs" \
--wrap="/projects1/malt/versions/malt040/malt-build \
--step 2 \
-i /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna.gz \
-s DNA \
-d /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/maltindexed \
-t 112 -a2taxonomy /projects1/microbiome_calculus/evolution/01-data/databases/malt/raw/nucl_acc2tax-May2017.abin"


# all Pasolli, et al. 2019 MAGs are here /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/
# all oral or non-western stool Pasolli, et al. 2019 MAGs are here /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest
# cat'd into one files with 
cat *.fa > Pasolli2019MAGs.fasta
# need to combine these with the RefSeq genomes James used to make the Custom RefSeq database to the folder here
/projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz

# as below:

#!/usr/bin/env bash
sbatch \
-c 2 \
--mem 4G \
--partition=medium \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-user=velsko@shh.mpg.de \
-J "catmalt" \
--wrap="cat /projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest/Pasolli2019MAGs.fasta.gz > /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20191015.fna && pigz -n2 /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20191015.fna"
#--wrap="zcat /projects1/microbiome_sciences/reference_databases/refseq/genomes/bacteria_archea_homo_20181122/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_20181122.fna.gz | cat - /projects1/microbiome_sciences/reference_databases/Pasolli2019_MAGs/representatives/oral_nonwest/Pasolli2019MAGs.fasta > /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna && pigz -n2 /projects1/microbiome_sciences/reference_databases/refseq_Pasolli2019MAGS/refseq_genomes_bacteria_archaea_homo_complete_chromosome_scaffold_Pasolli2019MAGs_20190930.fna"

# then run the malt build script to use all for taxonomic identification
# then need to create a tree of all of the same genomes used to build this new MALT database with PhyloPhlan2 (this is not easy to install yet, the conda install isn't ready yet)
# then need to convert the tree from PhyloPhlan2 into NCBI format for MEGAN

# use this to run MALT
#!/usr/bin/env bash
sbatch \
-c 112 \
--mem 1850000 \
--partition=supercruncher \
-o ~/slurm_logs/slurm.%j.out \
-e ~/slurm_logs/slurm.%j.err \
--mail-type=fail \
--mail-type=time_limit \
--mail-user=velsko@shh.mpg.de \
-J "MaltCMCnt" \
--wrap="/projects1/microbiome_calculus/evolution/02-scripts.backup/007-malt-genbank-nt_2017_2step_85pc_supp_0.01 \
/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp/*.gz \
/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/nt-correct"

# in 02-scripts.backup
# 011-imv-maltstats.sh
# To get the mapping stats from malt runs to input into R, use the log output file and run the following code:
# malt-nt CMC only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190903.log > ../00-documentation.backup/CMC_nt_numbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190903.log > ../00-documentation.backup/CMC_nt_aligned.txt
ls ../04-analysis/malt/nt/*.rma6 > ../00-documentation.backup/CMC_nt_names.txt
paste ../00-documentation.backup/CMC_nt_names.txt ../00-documentation.backup/CMC_nt_numbers.txt ../00-documentation.backup/CMC_nt_aligned.txt > ../00-documentation.backup/CMC_nt_aligned_stats.tsv

# malt-RefSeqCustom CMC only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190925.log > ../00-documentation.backup/CMCnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190925.log > ../00-documentation.backup/CMCaligned.txt
ls ../04-analysis/malt/RefSeqCustom/*.rma6 | grep -v SRR | grep -v JAE > ../00-documentation.backup/CMCnames.txt
paste ../00-documentation.backup/CMCnames.txt ../00-documentation.backup/CMCnumbers.txt ../00-documentation.backup/CMCaligned.txt > ../00-documentation.backup/CMC_RSC_aligned_stats.tsv

# malt-RefSeqCustom HMP only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20190930.log > ../00-documentation.backup/HMPnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20190930.log > ../00-documentation.backup/HMPaligned.txt
ls ../04-analysis/malt/RefSeqCustom/SRR*.bam.rma6 > ../00-documentation.backup/HMPnames.txt
paste ../00-documentation.backup/HMPnames.txt ../00-documentation.backup/HMPnumbers.txt ../00-documentation.backup/HMPaligned.txt > ../00-documentation.backup/HMP_RSC_aligned_stats.tsv

# malt-RefSeqCustom JAE only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20191021.log > ../00-documentation.backup/JAEnumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20191021.log > ../00-documentation.backup/JAEaligned.txt
ls ../04-analysis/malt/RefSeqCustom/JAE*.rma6 > ../00-documentation.backup/JAEnames.txt
paste ../00-documentation.backup/JAEnames.txt ../00-documentation.backup/JAEnumbers.txt ../00-documentation.backup/JAEaligned.txt > ../00-documentation.backup/JAE_RSC_aligned_stats.tsv

# malt-RefSeqCustom Yanomami only
grep "Num. of queries:" ../00-documentation.backup/malt-genbank_rma_20191218.log > ../00-documentation.backup/Yanomaminumbers.txt
grep "Aligned queries:" ../00-documentation.backup/malt-genbank_rma_20191218.log > ../00-documentation.backup/Yanomamialigned.txt
ls ../04-analysis/malt/RefSeqCustom/SRR*.truncated.rma6 > ../00-documentation.backup/Yanomaminames.txt
paste ../00-documentation.backup/Yanomaminames.txt ../00-documentation.backup/Yanomaminumbers.txt ../00-documentation.backup/Yanomamialigned.txt > ../00-documentation.backup/Yanomami_RSC_aligned_stats.tsv

# combine CMC, HMP, and JAE RefSeqCustom stats files
cat ../00-documentation.backup/CMC_RSC_aligned_stats.tsv ../00-documentation.backup/HMP_RSC_aligned_stats.tsv ../00-documentation.backup/JAE_RSC_aligned_stats.tsv ../00-documentation.backup/Yanomami_RSC_aligned_stats.tsv > ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_nt_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/HMP_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_JAE_RSC_aligned_stats.tsv

perl -p -i -e 's/ //g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv
perl -p -i -e 's/Num.ofqueries://g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv
perl -p -i -e 's/Alignedqueries://g' ../00-documentation.backup/CMC_HMP_JAE_Yano_RSC_aligned_stats.tsv

rm ../00-documentation.backup/*numbers.txt
rm ../00-documentation.backup/*aligned.txt
rm ../00-documentation.backup/*names.txt

# now add column titles (SampleID, Queries, Aligned) with ./add_malt_stats_headers.rb

##########################################################################################
# symlink the HMP data for Eager processing (and subsampling)
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061294
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062298
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062299
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513165
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513768
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513775
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514202
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514239
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514306
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR514329
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061192
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061320
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061365
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR061562
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR062083
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR063517
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR1804664
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR1804823
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR512767
ln -s /projects1/microbiome_calculus/evolution/01-data/public_data/raw/SRR513828

# subsample the HMP samples to 10000000 reads each to be more similar to the read number of the CMC samples

#!/bin/bash

#SBATCH -n 8
#SBATCH --mem 24G
#SBATCH --partition=medium
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH --export=ALL
#SBATCH --array=0-19%2
#SBATCH -J "subsample"

SAMPLES=($(find /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/*/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d_ -f 1))
SAMPLENAME=${SAMPLES[$SLURM_ARRAY_TASK_ID]}

seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R1_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R2_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R2_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/03-preprocessing/human_filering/input/public_data/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R2_000.10M.fastq

# symlink the JAE data for Eager processing (and subsampling)
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE006.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE007.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE008.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE009.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE010.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE012.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE013.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE014.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE015.A0101
ln -s /projects1/microbiome_sciences/raw_data/internal.backup/JAE016.A0101

#!/bin/bash

#SBATCH -n 8
#SBATCH --mem 24G
#SBATCH --partition=medium
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH --export=ALL
#SBATCH --array=0-19%2
#SBATCH -J "subsample"

SAMPLES=($(find /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d_ -f 1))
SAMPLENAME=${SAMPLES[$SLURM_ARRAY_TASK_ID]}

# need to run conda activate py27 before running /projects1/microbiome_calculus/Cameroon_plaque/02-scripts.backup/014-imv-humann2.sh
seqtk sample -s100 /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"/"$SAMPLENAME"_S0_L001_R1_000.fastq.gz 10000000 > /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq
pigz -8 /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/malt/input-temp_JAE/"$SAMPLENAME"10M/"$SAMPLENAME"_S0_L001_R1_000.10M.fastq

##################################################################

# to change the names of the HUMAnN2 folders that didn't match the basename do
rename 's/_S0_L001_R1_001.fastq.combined.fq.prefixed.extractunmapped.bam.10M.fastq.gz/.10M/' *_S0_L001_R1_001.fastq.combined.fq.prefixed.extractunmapped.bam.10M.fastq.gz
rename 's/_S0_L001_R1_000.10M.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz/.10M/' *_S0_L001_R1_000.10M.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz
rename 's/_S0_L001_R1_000.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz//' *_S0_L001_R1_000.fastq.combined.fq.prefixed.extractunmapped.bam.fastq.gz
rename 's/.fastq.truncated.prefixed.gz//' *.fastq.truncated.prefixed.gz


mkdir genefamilies pathabundance pathcoverage

ls | while read line; do cp $line/*genefamilies.tsv ./genefamilies; done
ls | while read line; do cp $line/*pathabundance.tsv ./pathabundance; done
ls | while read line; do cp $line/*pathcoverage.tsv ./pathcoverage; done

# merge the output files and normalize them for direct comparison of samples within each output type
humann2_join_tables -i genefamilies -o humann2.genefamilies.all.tsv
humann2_renorm_table -i humann2.genefamilies.all.tsv -o humann2.genefamilies.all.tss.tsv -s y

humann2_join_tables -i pathabundance -o humann2.pathabundance.all.tsv
humann2_renorm_table -i humann2.pathabundance.all.tsv -o humann2.pathabundance.all.tss.tsv -s n

humann2_join_tables -i pathcoverage -o humann2.pathcoverage.all.tsv
humann2_renorm_table -i humann2.pathcoverage.all.tsv -o humann2.pathcoverage.all.tss.tsv -s n

mkdir genefamilies/renormed
for f in ./genefamilies/*.tsv; do humann2_renorm_table -i $f -o ./genefamilies/renormed/$(basename $f .tsv).tss.tsv; done

# download databases for regrouping entries
humann2_databases --download utility_mapping full /projects1/users/velsko/bin/humann2_regroup_databases

humann2_join_tables -i ./genefamilies/renormed -o ./humann2.genefamilies.all.i.tss.tsv
humann2_regroup_table --input humann2.genefamilies.all.i.tss.tsv --output ./humann2.genefamilies.all.i.tss.ko.tsv --groups uniref90_ko
humann2_renorm_table -i ./humann2.genefamilies.all.i.tss.ko.tsv -o ./humann2.genefamilies.all.i.tss.renorm.ko.tsv -s y

# To determine the # of reads that were aligned (or rather unaligned) by HUMAnN2
# working dir /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/humann2/input
ls *.gz > samples.list
touch samples.lines
for f in *.gz; do zcat $f | wc -l >> samples.lines; done
# add a header to each file (SampleID, Lines)
paste samples.list samples.lines > ../../../05-results.backup/sample_lines.tsv 
# check that these numbers, divided by 4, are the same as those in the metadata file column Individual_Seq_Depth_NonHuman
# if they are, use that metadata column for the R analyses, otherwise figure out why that column is wrong and fix it to match these. Use it with the correct numbers

cd ../logfiles/
touch files.names unaligned.pcts
for f in *.out; do grep "Creating output" $f | sed 's/Creating\ output\ directory\:\ \/projects1\/microbiome_calculus\/Cameroon_plaque\/04-analysis\/humann2\/output\///g' >> files.names; done
for f in *.out; do grep "Unaligned reads after translated alignment:" $f | sed 's/Unaligned\ reads\ after\ translated\ alignment\://g' | sed 's/\ \%//g' >> unaligned.pcts; done
# add a header to each file (SampleID, UnalignedPct)
paste files.names unaligned.pcts > ../../../05-results.backup/humann2_alignment_stats.tsv


###########################
run kraken 5X with both databases to see if there are more reads assigned when including MAGs, account for variability with the 5 runs
# get the number of classified and unclassified reads for each sample for each run with each database to compare 
# if adding the Pasolli MAGs to the database increases the number of reads classified in each sample

# **Note** there was no difference in the number of reads assigned in each sample between the 5 runs, so when running again use only 3 runs

# the MetaPhlAn2-type output may be too difficult to work with, so re-run with 3 runs each using the standard output format

# **Note** there is a problem with Kraken2, where it will call reads classified 'C' but have them at rank '0'
# in the report file then, the number of unclassified + root reads doesn't equal the total. The missing reads are those above. 
# These reads are not included in the report file, but are included in the output file. Apparently the developers are aware of the problem and working on it

# run this for both outputs (RefSeqOnly, RefSeqPasolliMAGs). Add .rso to the files that had the RefSeqOnly database
ls *.output.* > sampleorder.rso.list
ls *.output.* > sampleorder.rspm.list

touch classifiedreads.rso.counts
for f in *.output.*; do grep -c "^C" $f >> classifiedreads.rso.counts; done
touch unclassifiedreads.rso.counts
for f in *.output.*; do grep -c "^U" $f >> unclassifiedreads.rso.counts; done

# open each file (sampleorder.list, classifiedreads.counts, unclassifiedreads.counts) and give each a header
# SampleID, Classified, Unclassified, respectively

paste sampleorder.rspm.list classifiedreads.rspm.counts unclassifiedreads.rspm.counts > readclassification_stats.rspm.tsv
paste sampleorder.rso.list classifiedreads.rso.counts unclassifiedreads.rso.counts > readclassification_stats.rso.tsv
cp readclassification_stats.rspm.tsv /projects1/microbiome_calculus/Cameroon_plaque/05-results.backup/readclassification_stats.rspm.tsv
cp readclassification_stats.rso.tsv /projects1/microbiome_calculus/Cameroon_plaque/05-results.backup/readclassification_stats.rso.tsv

# Now load these files (readclassification_stats.tsv, readclassification_stats.rso.tsv) into R to compare the number of classified reads. Is it higher when using the database with the Pasolli MAGs?

# to get taxonomy for the standard report files:
# in /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqOnly/no_header
# in /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqPasolliMAGs/no_header

touch taxonomy.list
for f in *.old
do
awk -F"\t" '{print $1}' $f >> taxonomy.list
done
sort taxonomy.list | uniq > taxonomy.list.uniq


touch taxonomy.list
for f in *.old
do
awk -F"\t" '{print $1}' $f >> taxonomy.list
done
sort taxonomy.list | uniq > taxonomy.list.uniq

awk -F"\|" '{print $NF}' taxonomy.list.uniq | sed 's/d__//g' | sed 's/p__//g' | sed 's/c__//g' | sed 's/o__//g' | sed 's/f__//g' | sed 's/g__//g' | sed 's/s__//g' | paste - taxonomy.list.uniq > taxonomy.list.uniq.split
cat /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqPasolliMAGs/no_header/taxonomy.list.uniq.split /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/kraken/output/mpa_output/RefSeqOnly/no_header/taxonomy.list.uniq.split | sort | uniq > /projects1/microbiome_calculus/Cameroon_plaque/00-documentation.backup/taxonomy.list.uniq.split

# open file and add column names SciName and Taxonomy

# open taxonomy_na.tsv and add in the appropriate taxonomy

###########################
To download oral bacteriophage sequences from MG-RAST

wget ftp://ftp.metagenomics.anl.gov/tools/download/mg-download.py
chmod u+x mg-download.py

source activate 2.7
mg-download.py --project mgp7236 --dir /projects1/microbiome_sciences/raw_data/public/abeles2014

# run the Abeles 2014 data through FastQC to see if there are adapters that need removing
TACGAGTATGCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG	
CGTAGACTAGCCTACGGGAGGCAGCAGTGAGGAATATTGGTCAATGGGCG
ACGACTACAGCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG
ACGAGTGCGTCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG


# try running the reads through cutadapt to match the parameters that were used by Abeles, et al. 2014
cutadapt -a GCCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACG -m 50 -M 300 --max-n 0.25 -j <NumberOfCores> -o <output.fastq.gz> <input.fastq.gz>
cutadapt -u 10 -o trimmed.fastq reads.fastq # to cut off 10 bases from the begining


# assemble the phage reads with SPAdes
sbatch 018-assemblephage.sh

# check assemblies with quast (or metaquast?)
019-imv-quast.sh /projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/scaffolds.list


# index the phage sequences from the assemblies in /projects1/microbiome_calculus/Cameroon_plaque/01-data/databases
bwa index -p abeles2014phage /projects1/microbiome_calculus/Cameroon_plaque/01-data/databases/abeles2014phage.fastq.gz




find /projects1/microbiome_sciences/raw_data/public/abeles2014/ -name '*.gz' -type f | rev | cut -d/ -f 1 | rev | cut -d. -f 1 | awk '{print "/projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/"$1"/scaffolds.fasta"}' > contig.list


find /projects1/microbiome_calculus/Cameroon_plaque/01-data/phage/abeles2014assemblies/SPAdes/*/ -name '*ds.fasta' -type f | rev | cut -d/ -f 2 | rev | cut -d. -f1 | grep -v K | grep -v misc

########################################################

# assemble the data

nextflow run nf-core/mag \
--reads '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/input/*.R{1,2}.fastq.gz' \
-profile shh \
--kraken2_db 'ftp://ftp.ccb.jhu.edu/pub/data/kraken2_dbs/minikraken2_v2_8GB_201904_UPDATE.tgz'  \
--outdir '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output' \
-name 'cmc_assembly' \
-w '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output/work'

# this is the database Alex made, but it doesn't work with this pipeline
# --kraken2_db '/projects1/microbiome_sciences/reference_databases/refseq20191017_Pasolli2019/kraken2_db/for_nf-core-mag/MiniKraken_RefSeq1910PlusPasolliSGBs.tar.gz'  \


# to resume a stalled run after deleting files
nextflow run nf-core/mag --reads '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/input/*.R{1,2}.fastq.gz' -profile shh --kraken2_db 'ftp://ftp.ccb.jhu.edu/pub/data/kraken2_dbs/minikraken2_v2_8GB_201904_UPDATE.tgz'  --outdir '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output' -w '/projects1/microbiome_calculus/Cameroon_plaque/04-analysis/assembly/output/work' -resume cmc_assembly


########################################################

snakemake -s aadder.Snakefile --cluster-config aadder-cluster.config --cluster 'sbatch --mem {cluster.mem} -p {cluster.partition} -o {cluster.out} -e {cluster.err} -n {threads}' -j 1 -n # for a test run

snakemake -s aadder_SEED_fada_ols.Snakefile --cluster-config fa_seed-cluster.config --cluster 'sbatch --mem {cluster.mem} -p {cluster.partition} -o {cluster.out} -e {cluster.err} -n {threads}' -j -n # for a test run

########################################################
# Taxonomy differences between Kraken assignemnts with RefSeqOnly and RefSeq+PasolliMAGs
# pre-MetacodeR file fixes
# fixing the taxonomy names in 00-documentation.backup/all_taxonomy_filtered_hand.csv
sed 's/VIruses/Viruses/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed.csv
sed 's/root\|d__Viruses/root\|_d__Viruses/g' all_taxonomy_filtered_hand-fixed.csv > all_taxonomy_filtered_hand-fixed2.csv
rm all_taxonomy_filtered_hand-fixed.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Eukaryota/root\|_d__Eukaryota/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
sed 's/Eukaryotas/Eukaryota/g' all_taxonomy_filtered_hand-fixed2.csv > all_taxonomy_filtered_hand-fixed3.csv
rm all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed3.csv all_taxonomy_filtered_hand.csv
sed 's/d__Eukaryota/d__Fungi/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Fungi/root\|_d__Fungi/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/\|k__Fungi//g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Bacteria/root\|_d__Bacteria/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv
sed 's/root\|d__Archaea/root\|_d__Archaea/g' all_taxonomy_filtered_hand.csv > all_taxonomy_filtered_hand-fixed2.csv
mv all_taxonomy_filtered_hand-fixed2.csv all_taxonomy_filtered_hand.csv



########################################################
# Songbird for differential abundance

# convert species and genus tables into biom format
biom convert -i malt_species_decontam.tsv -o malt_species_decontam.biom --to-hdf5 --table-type="OTU table"
biom convert -i malt_species_cmc_decontam.tsv -o malt_species_cmc_decontam.biom --to-hdf5 --table-type="OTU table"
biom convert -i malt_genus_decontam.tsv -o malt_genus_decontam.biom --to-hdf5 --table-type="OTU table"
biom convert -i malt_genus_cmc_decontam.tsv -o malt_genus_cmc_decontam.biom --to-hdf5 --table-type="OTU table"

# to check that the conversion worked try:
biom convert -i malt_genus_decontam.biom -o otu_table.txt --to-tsv

# run Tensorboard:
tensorboard --logdir .

# Tensorboard url:
http://mpi-sdag1.sdag.ppj.shh.mpg.de:6006

# For the formula pick from the parameters:
Ethnic_Group+Village+Market_economy+Market_economy_split+Age_group+Sex+Tooth_site

# done: malt_genus_decontam.biom, malt_genus_cmc_decontam.biom, malt_species_decontam.biom, malt_species_cmc_decontam.biom

## Industrial and Cameroon samples
# for genus this plateaus below the null model and has a lower cross-validation error and lower loss
# for species this plateaus below the null model and has a lower cross-validation error and lower loss

--form0 "1" # this is the null model
--form1 "C(Env, Treatment('HunterGatherer'))"


## Cameroon samples only
# for genus form1, form2 form3, form 4 plateau below the null model and have the lowest cross-validation errors (form1 loss is slightly lower than form3, cv-error is nearly identical)
# for genus form2, form 4 plateau below the null model and have lower cross-validation errors but are higher than form1/form3 (form 2 is just below the null model)
# for species form1 plateaus below the null model and has the lowest cross-validation error; form3 plateaus at the same place as the null model and form2/form4 plateau above the null model
# for species form1/form3 both have lower cv-error and lower loss than the null model, with form 1 lower for both

--form0 "1" # this is the null model
--form1 "C(Ethnic_Group, Treatment('Nzime'))"
--form2 "C(Market_economy, Treatment('Farming'))"
--form3 "C(Tooth_site, Treatment('Posterior'))"
--form4 "C(Sex, Treatment('Male'))"



#!/bin/bash

#SBATCH -n 4
#SBATCH --mem 24G
#SBATCH --partition=short
#SBATCH -o /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.out
#SBATCH -e /projects1/clusterhomes/velsko/slurm_logs/slurm.%j.err
#SBATCH --mail-type=fail
#SBATCH --mail-type=time_limit
#SBATCH --mail-use=velsko@shh.mpg.de
#SBATCH -J "songbird"

songbird multinomial \
        --input-biom /projects1/microbiome_calculus/Cameroon_plaque/05-results.backup/malt_species_decontam.biom \
        --metadata-file /projects1/microbiome_calculus/Cameroon_plaque/00-documentation.backup/01-cameroon_hunter_gatherer_metadata.tsv \
        --formula "C(Env,Treatment('HunterGatherer'))" \
        --epochs 10000 \
        --differential-prior 0.5 \
        --summary-interval 1 \
        --summary-dir /projects1/microbiome_calculus/Cameroon_plaque/04-analysis/songbird/species_noblanks/formTest

# need to copy the differentials.tsv files into 05-results.backup for upload to Rmd files
cp ../04-analysis/songbird/species_noblanks/form1/differentials.tsv ./songbird_noblanks_species_env.tsv
cp ../04-analysis/songbird/species_cmc/form1/differentials.tsv ./songbird_cmc_species_eg.tsv
cp ../04-analysis/songbird/species_cmc/form2/differentials.tsv ./songbird_cmc_species_me.tsv
cp ../04-analysis/songbird/species_cmc/form3/differentials.tsv ./songbird_cmc_species_ts.tsv
cp ../04-analysis/songbird/species_cmc/form4/differentials.tsv ./songbird_cmc_species_sex.tsv
cp ../04-analysis/songbird/genus_noblanks/form1/differentials.tsv ./songbird_noblanks_genus_env.tsv
cp ../04-analysis/songbird/genus_cmc/form1/differentials.tsv ./songbird_cmc_genus_eg.tsv
cp ../04-analysis/songbird/genus_cmc/form2/differentials.tsv ./songbird_cmc_genus_me.tsv
cp ../04-analysis/songbird/genus_cmc/form3/differentials.tsv ./songbird_cmc_genus_ts.tsv
cp ../04-analysis/songbird/genus_cmc/form4/differentials.tsv ./songbird_cmc_genus_sex.tsv







########################################################
# BacDiveR

# Search on 23 September 2020
# Search query for Gram stain, spore formation, oxygen tolerance, metabolite utilization, kind of utilization: carbon source

https://bacdive.dsmz.de/advsearch?site=advsearch&searchparams%5B42%5D%5Bsearchterm%5D=*&searchparams%5B254%5D%5Bsearchterm%5D=*&searchparams%5B921%5D%5Bsearchterm%5D=*&searchparams%5B344%5D%5Bcontenttype%5D=text&searchparams%5B344%5D%5Btypecontent%5D=contains&searchparams%5B344%5D%5Bsearchterm%5D=*&searchparams%5B346%5D%5Bsearchterm%5D=carbon+source&advsearch=search

########################################################
# eager2 to remove human reads for upload to ENA

nextflow run nf-core/eager \
-r 2.2.1 \
-profile microbiome_screening,shh \
--outdir /projects1/microbiome_calculus/Cameroon_plaque/01-data/eager2_for_ENA/eager2 \
-work-dir /projects1/microbiome_calculus/Cameroon_plaque/01-data/eager2_for_ENA/work \
--input /projects1/microbiome_calculus/Cameroon_plaque/01-data/eager2_for_ENA/cmc_eager2.tsv \
--complexity_filter_poly_g \
--fasta /projects1/Reference_Genomes/Human/HG19/hg19_complete.fasta \
--bwa_index /projects1/Reference_Genomes/Human/HG19/ \
--bwaalnn 0.02 \
--bwaalnl 1024 \
--hostremoval_input_fastq \
--hostremoval_mode remove \
--skip_damage_calculation \
--skip_qualimap \
--email velsko@shh.mpg.de \
-name cmc_strip \
-with-tower

########################################################

# During the final stages of analysis, a mistake was discovered in the index assignments of one 
# library batch in Pandora (they had been shifted down by 1 line), as well as incorrect naming 
# of 2 samples, one of which is in the batch with mixed indices. This means that when the raw 
# read data was demultiplexed, the readsets with indices from this batch were assigned the wrong sequencing ID. 

# This was corrected in Pandora and the reads de-multiplexed to have the correct ID assigned to each raw read set.

# Rather than re-run all analyses with the newly demultiplexed data, which would take several months, 
# the sample names were corrected in the names of all output files in 04-analysis folders. 

# For MALT and AADDER tables, the re-named rma6 files were uploaded into MEGAN. New .megan comparison 
# files were saved and new species and genus tables exported, with the same name as the original but 
# adding '_corrected' to the end of the file name, with the exception of the nt database run.
# The rma6 files for the MALT nt run had been deleted, so the output tables had the names corrected 
# within the file, instead of generating a new file. 

Initial	Correct
CMC009.B0101	CMC008.A0101
CMC011.B0101	CMC009.B0101
CMC016.A0102	CMC011.B0101
CMC018.A0101	CMC016.A0102
CMC020.A0101	CMC018.A0101
CMC024.A0101	CMC020.A0101
CMC026.A0101	CMC024.A0101
CMC028.A0101	CMC026.A0101
CMC030.A0101	CMC028.A0101
CMC034.A0101	CMC030.A0101
CMC036.A0101	CMC034.A0101
CMC042.B0101	CMC036.A0101
CMC008.A0101	CMC042.B0101
CMC016.A0101	CMC016.B0101
CMC016.A0102	CMC016.A0101






















